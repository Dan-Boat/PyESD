<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Methods &mdash; pyESD 1.0.1 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="tutorials" href="tutorials.html" />
    <link rel="prev" title="Installation" href="installation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            pyESD
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Methods</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#modelling-framework">Modelling framework</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="tutorials.html">tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Practical examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="gallery.html">Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="modules.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">pyESD</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Methods</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/methods.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="methods">
<h1>Methods<a class="headerlink" href="#methods" title="Permalink to this heading"></a></h1>
<p>The modeling steps and framework require to generate station-based downscaling products are explianed further here. The PP-ESD downscaling cycle involves technical and laborious steps that must be carefully
addressed to ensure the robustness and accuracy of local-scale climate predictions. We provide more details on the various methods of the PP-ESD modelling routines</p>
<a class="reference internal image-reference" href="_images/outline1.png"><img alt="Picture" src="_images/outline1.png" style="width: 600px;" /></a>
<section id="modelling-framework">
<h2>Modelling framework<a class="headerlink" href="#modelling-framework" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p><strong>Predictors construction and selections</strong></p></li>
</ul>
<hr class="docutils" />
<p>The PP-ESD approach relies heavily on selecting the right predictors and learning models, as noted by Maraun et al. (2019) and Gutiérrez et al. (2019).
These PP-ESD models are empirical, which means they use predictors as stand-ins for the various physical processes influencing the local climate.
So, it’s crucial that the chosen predictors provide enough information to capture the variability in what you’re trying to predict.</p>
<p>To choose predictors wisely, it’s essential to understand how the atmospheric variability in your study area. For instance, large-scale climate phenomena like atmospheric teleconnection patterns
often dominate regional climate variations. Therefore, considering these as potential predictors is a good idea. To make the selection process manageable, you can employ statistical techniques,
like feature selection or dimension reduction. These methods help trim down the list of potential predictors to a more manageable set of variables that show strong statistical relationships with
what you want to predict. This not only improves the model’s performance but also helps tackle issues like multicollinearity (when predictors are highly correlated) and overfitting (when the model
fits the training data too closely).</p>
<p>In the pyESD package, you can explore three different wrapper feature selection techniques for various models:</p>
<ol class="arabic simple">
<li><p><strong>Recursive Feature Elimination:</strong> This method, as explained by Chen and Jeong (2007), iteratively removes the least important predictors until the best subset is found.</p></li>
<li><p><strong>Tree-Based Feature Selection:</strong> This technique, based on Zhou et al. (2021), uses decision trees to identify the most influential predictors.</p></li>
<li><p><strong>Sequential Feature Selection:</strong> As described by Ferri et al. (1994), this method explores different combinations of predictors to find the most informative subset.</p></li>
</ol>
<p>You can find these methods in the <code class="docutils literal notranslate"><span class="pre">pyESD.feature_selection</span></code> module under the names <code class="docutils literal notranslate"><span class="pre">RecursiveFeatureElimination</span></code>, <code class="docutils literal notranslate"><span class="pre">TreeBasedSelection</span></code>, and <code class="docutils literal notranslate"><span class="pre">SequentialFeatureSelection</span></code>, respectively.</p>
<p>The predictor selection method is applied before training the model in the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method by setting the predictor selector_parameter to True. The cal_relative_importance is set to True if the feature
importance or explained variance of each predictor is computed (e.g.):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>SO.fit(variable, date_range, predictor_data, fit_predictors=True, predictor_selector=True,
                 selector_method=’Recursive’, selector_regressor=&quot;ARD&quot;,
                 cal_relative_importance=False)
</pre></div>
</div>
<p>Note that the default fit method drops missing values and does not incorporate the information at
these timestamps when calibrating the model due to their potential implications in interpreting the model.
However, if users find merit in replacing the missing values, the impute parameter must be set to True, and
the method should be specified (e.g., linear):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">SO</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">date_range</span><span class="p">,</span> <span class="n">predictor_data</span><span class="p">,</span> <span class="n">fit_predictors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">predictor_selector</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">selector_method</span><span class="o">=</span><span class="s1">&#39;Recursive&#39;</span><span class="p">,</span> <span class="n">selector_regressor</span><span class="o">=</span><span class="s1">&#39;ARD&#39;</span><span class="p">,</span> <span class="n">impute</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                         <span class="n">impute_method</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Additionally, the pyESD package includes classical filter feature selection techniques, like correlation analyses, as part of the weather station object. These techniques help you identify predictors that correlate well with your predictand.
The predictor_correlation method of the station object is used for the correlation analysis:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">corr</span> <span class="o">=</span> <span class="n">SO</span><span class="o">.</span><span class="n">predictor_correlation</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">predictor_data</span><span class="p">,</span> <span class="n">predictor_data</span><span class="p">,</span> <span class="n">fit_predictor</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">fit_predictand</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;pearson&quot;</span><span class="p">,</span> <span class="n">use_scipy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>In practice, predictors are often created by either computing regional averages of relevant climate variables or constructing time series indices for significant large-scale climate phenomena.</p>
<ul class="simple">
<li><p><strong>Learning model selection</strong></p></li>
</ul>
<hr class="docutils" />
<p>The relationship between local climate predictions and large-scale factors is often intricate due to the complexities within the climate system. Machine Learning (ML) algorithms,
however, have proven effective in uncovering hidden patterns in climate data. These patterns are crucial for constructing sophisticated models that can accurately predict local
climate changes.
Neural networks, for instance, have gained attention in downsizing climate information. They excel at establishing complex, nonlinear connections between local predictions and
large-scale factors. Support Vector Machine (SVM) models are another choice; they map low-dimensional
data to high-dimensional feature spaces using kernel functions. This technique captures the intricate links between predictors and predictions.
Furthermore, some studies utilize multi-model ensembles to mitigate model variance and replicate the distribution of training data.
Selecting the right model or algorithm for a specific location or prediction can be challenging. Factors like data complexity, distribution, temporal resolution, and interpretability
need consideration. Unfortunately, climate data downscaling lacks well-established frameworks.
The pyESD package tackles this challenge by offering a variety of ML models, each with distinct theoretical foundations, assumptions, and structures. This versatility empowers
researchers to experiment with different models, replicate findings, and adapt to emerging recommendations for specific predictions and regions. Most of the statistical and ML models in
pyESD are built upon the open-source scikit-learn framework.</p>
<p><strong>Here’s a list of the regression models implemented in the provided Python code</strong>:</p>
<ol class="arabic simple">
<li><p><strong>LassoCV</strong>: Lasso regression with cross-validation.</p></li>
<li><p><strong>LassoLarsCV</strong>: LassoLars regression with cross-validation.</p></li>
<li><p><strong>RidgeCV</strong>: Ridge regression with cross-validation.</p></li>
<li><p><strong>ARD</strong>: Automatic Relevance Determination regression.</p></li>
<li><p><strong>BayesianRidge</strong>: Bayesian Ridge regression.</p></li>
<li><p><strong>Gamma</strong>: Gamma Regressor (Generalized Linear Model).</p></li>
<li><p><strong>Poisson</strong>: Poisson Regressor (Generalized Linear Model).</p></li>
<li><p><strong>MLP</strong>: Multi-layer Perceptron Regressor (Neural Network).</p></li>
<li><p><strong>SVR</strong>: Support Vector Regressor.</p></li>
<li><p><strong>RandomForest</strong>: Random Forest Regressor (Ensemble Tree-Based Model).</p></li>
<li><p><strong>ExtraTree</strong>: Extra Trees Regressor (Ensemble Tree-Based Model).</p></li>
<li><p><strong>Bagging</strong>: Bagging Regressor (Ensemble Model).</p></li>
<li><p><strong>AdaBoost</strong>: AdaBoost Regressor (Boosting Ensemble Model).</p></li>
<li><p><strong>HistGradientBoost</strong>: Histogram Gradient Boosting Regressor (Gradient Boosting Ensemble Model).</p></li>
<li><p><strong>GradientBoost</strong>: Gradient Boosting Regressor (Gradient Boosting Ensemble Model).</p></li>
<li><p><strong>XGBoost</strong>: XGBoost Regressor (Gradient Boosting Ensemble Model).</p></li>
<li><p><strong>SGD</strong>: Stochastic Gradient Descent Regressor.</p></li>
<li><p><strong>Stacking</strong>: Stacked Generalization Ensemble</p></li>
<li><p><strong>MLR</strong>: Multiple Linear Regression</p></li>
<li><p><strong>Dense</strong>: Various Deep Learning models</p></li>
</ol>
<p>These models cover a wide range of regression techniques, from traditional linear models to advanced ensemble methods and neural networks.</p>
<a class="reference internal image-reference" href="_images/outline2.png"><img alt="Picture" src="_images/outline2.png" style="width: 600px;" /></a>
<ul class="simple">
<li><p><strong>Learning model training and evaluation</strong></p></li>
</ul>
<hr class="docutils" />
<p>The stage of training and testing PP-ESD models stands as a critical juncture in the downscaling process. It significantly
influences the robustness of the final models and the accuracy of their predictions. This process typically involves the following steps:</p>
<ol class="arabic simple">
<li><p><strong>Data Splitting</strong>: The observational records are divided into two sets - training and testing datasets.</p></li>
<li><p><strong>Training Transfer Functions</strong>: The training datasets are used to create the transfer functions that constitute the PP-ESD models.</p></li>
<li><p><strong>Model Evaluation</strong>: The models are then assessed using independent testing datasets.</p></li>
</ol>
<p>In the model training phase, techniques like hyperparameter optimization (e.g., GridSearchCV) are employed to fine-tune parameters like
regression coefficients. This optimization aims to enhance the model’s performance. Cross-validation (CV) techniques come into play to break down
the training dataset into smaller segments for iterative model assessment and improvement. These techniques also help guard against overfitting.</p>
<p>Among CV techniques, the k-fold framework is most commonly used in climate data downscaling models. It splits the training data into k equal and
separate subsamples, often called “folds”. In each iteration, one fold serves as the validation set, and the
remaining k-1 folds form the training data. The leave-one-out CV technique offers an alternative and has been employed
in ESD model development.</p>
<p>CV techniques rely on the assumption that the data is independent and identically distributed (i.i.d), treating it as if it’s generated without memory
of past samples. However, this assumption may not hold for time series data due to seasonal effects, for instance. To address
this, the pyESD package incorporates monthly-bootstrapped resampling and time-series splitters.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">pyESD.splitter</span></code> module includes various CV frameworks for model training, such as k-fold, leave-one-out, and others. Validation metrics, like the coefficient of determination (R2),
Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and more, are used to optimize model parameters. The final values for these metrics, reflecting the model’s
performance during training, are the arithmetic means across all iterations. In this paper, we refer to them as CV performance metrics (i.e., CV R2, CV RMSE, and CV MAE).
The model is defined in the set_model method, with the method parameter as the model name listed above. The cost function for training
the model is also defined in the scoring parameter, and the splitter to use for cross-validation is defined by the CV parameter. In case the regressor used is
the ensemble method, then ensemble learning must be defined as True (e.g.):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>SO.set_model(variable, method=”Stacking”, ensemble_learning=True,
                  estimators=base_estimators, final_estimator_name=final_estimator, daterange=from1958to2010, predictor_dataset=ERA5Data, cv=KFold(n_splits=10),
                  scoring = scoring)
</pre></div>
</div>
<ul class="simple">
<li><p><strong>Coupling of the transfer function to GCMs</strong></p></li>
</ul>
<p>Circulation Model (GCM) simulations driven by different greenhouse gas concentration scenarios. PP-ESD, being a bias-free downscaling method, offers
flexibility by being compatible with various GCMs, provided that the GCMs adequately represent the predictors. To address this, standardizing the simulated
predictors can help. An analysis can be performed to assess the similarity in the distribution of observed and simulated predictors. For
instance, the Kolmogorov-Smirnov (KS) test, available as part of the pyESD package utilities, can be used to test the null hypothesis (H_0) that observation-based
and simulated predictors follow the same theoretical distribution.</p>
<p>The coupling of ESD with GCMs involves several steps:</p>
<p>1. <strong>Recreating Predictors</strong>: Utilize GCM output to recreate the predictors used during the training of the ESD model. This process may
range from constructing simple regional temperature means to reconstructing more complex climate phenomena through multivariate indices.</p>
<p>2. <strong>Index-Based Predictors</strong>: For indices like NAO, EA, SCAN, and others, simulate the indices by projecting GCM pressure anomalies
onto the Empirical Orthogonal Function (EOF) loading patterns of the predictors. This ensures that the
physical meaning of the index values is preserved.</p>
<ol class="arabic simple" start="3">
<li><p><strong>ESD Model Application</strong>: The ESD model takes these simulated predictors as input and generates local-scale predictions using its transfer functions.</p></li>
<li><p><strong>Assessing Added Value</strong>: Evaluate the added value of the downscaled product by comparing it to the raw outputs of different GCMs and Regional Climate Models (RCMs).</p></li>
</ol>
<p>5. <strong>Applications</strong>: Utilize the high-resolution local-scale predictions to drive climate change impact assessment models. These predictions can inform various assessments,
such as flood frequency prediction, agricultural impact assessments, changes in water resources, and more.</p>
<p>This integration bridges the gap between large-scale climate models and fine-scale local predictions, enabling informed decision-making in various sectors impacted by climate change.
The future predictions are generated using the predict method with the simulated predictors as input data:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1">#print(&quot;predicting based on the RCP 2.6 predictors&quot;)</span>
<span class="n">yhat_CMIP5_RCP26_R1_anomalies</span> <span class="o">=</span> <span class="n">SO</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">variable</span><span class="p">,</span> <span class="n">fullCMIP5</span><span class="p">,</span>
                                     <span class="n">CMIP5_RCP26_R1</span><span class="p">,</span> <span class="n">fit_predictors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">fit_predictand</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                     <span class="n">params_from</span><span class="o">=</span><span class="s2">&quot;CMIP5_AMIP_R1&quot;</span><span class="p">,</span> <span class="n">patterns_from</span><span class="o">=</span> <span class="s2">&quot;CMIP5_AMIP_R1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="installation.html" class="btn btn-neutral float-left" title="Installation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="tutorials.html" class="btn btn-neutral float-right" title="tutorials" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Daniel Boateng.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>