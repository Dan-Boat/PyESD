<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>pyESD.MLR_model &mdash; pyESD 1.0.1 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            pyESD
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../methods.html">Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html">Using pyESD for Downscaling Climate Information</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples.html">Practical examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../testing.html">Testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">pyESD</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">pyESD.MLR_model</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for pyESD.MLR_model</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Created on Mon Nov  7 17:28:48 2022</span>

<span class="sd">@author: dboateng</span>

<span class="sd">This module contains the regression routines. There are three layers for</span>
<span class="sd">bootstrapped forward selection regression:</span>

<span class="sd">- The ``BootstrappedRegression`` class is the outer layer. This implements the</span>
<span class="sd">  bootstrapping loop. This class has &quot;regressor&quot; member that implements the</span>
<span class="sd">  single regression step (i.e. a fit and a predict method). This can be the a</span>
<span class="sd">  ``ForwardSelection`` object, but can also be ``Lasso`` from sklearn or</span>
<span class="sd">  similar routines.</span>
<span class="sd">- The ``ForwardSelection`` class is the next layer. This class implements a</span>
<span class="sd">  Forward Selection loop. This again has a regressor object that has to</span>
<span class="sd">  implement ``get_coefs``, ``set_coefs``, and ``average_coefs``. Additionally</span>
<span class="sd">  the regressor object has to implement ``fit_active``, ``fit``, and</span>
<span class="sd">  ``predict``.</span>
<span class="sd">  An example of such a regressor object is ``MultipleLSRegression``.</span>
<span class="sd">  </span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">copy</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1">#import statsmodels.api as sm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>


<span class="n">__all__</span> <span class="o">=</span>  <span class="p">[</span><span class="s2">&quot;BootstrappedRegression&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ForwardSelection&quot;</span><span class="p">,</span>
            <span class="s2">&quot;BootstrappedForwardSelection&quot;</span><span class="p">,</span>
            <span class="s2">&quot;MultipleLSRegression&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="k">class</span> <span class="nc">MetaEstimator</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Meta estimators are classes that implement ``fit`` and ``predict``, but don&#39;t perform the</span>
<span class="sd">    regression themselves. They all have a member variable ``regressor`` that performs this task.</span>
<span class="sd">    This class contains getters and setters that are simply the ones of the regressor object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">get_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_coefs</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coefs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_coefs</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
        <span class="c1"># set coef_ and intercept_ for ease of use</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">coef_</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;intercept_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;coefs_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coefs_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">coefs_</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;intercepts_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercepts_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">intercepts_</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>



<span class="c1">###############################################################################################</span>
<span class="c1"># BootstrappedRegression and ForwardSelection</span>
<span class="c1">###############################################################################################</span>

<div class="viewcode-block" id="BootstrappedRegression"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.BootstrappedRegression">[docs]</a><span class="k">class</span> <span class="nc">BootstrappedRegression</span><span class="p">(</span><span class="n">MetaEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a regression in a bootstrapping loop.</span>

<span class="sd">    This splits the data multiple times into training and test data and</span>
<span class="sd">    performs a regression for each split. In each loop</span>
<span class="sd">    the calculated parameters are stored. The final model uses the average of</span>
<span class="sd">    all predictors.</span>
<span class="sd">    If the model is a ``LinearModel`` from sklearn (i.e. it has the attributes</span>
<span class="sd">    ``coef_`` and ``intercept_``), the averaging routine does not have to be</span>
<span class="sd">    implemented. However, it can be implemented if something else than a</span>
<span class="sd">    arithmetic mean should be used (e.g. if only the average of robust</span>
<span class="sd">    predictors should be taken and everything else should be set to zero).</span>

<span class="sd">    Since this inherites from sklearn modules, it can to some extent be used</span>
<span class="sd">    interchangibly with other sklearn regressors.</span>


<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    regressor : regression object</span>
<span class="sd">        This should be an object similar to sklearn-like regressors that</span>
<span class="sd">        provides the methods ``fit(self, X_train, y_train, X_test, y_test)``</span>
<span class="sd">        and ``predict(self, X)``.</span>
<span class="sd">        This must also provide the methods ``get_coefs(self)``,</span>
<span class="sd">        ``set_coefs(self, coefs)``, and ``average_coefs(self, list_of_coefs)``.</span>
<span class="sd">        An example of this is ``ForwardSelection`` below.</span>
<span class="sd">        The regressor can also have a member variable ``additional_results``,</span>
<span class="sd">        which should be a dictionary of parameters that are calculated during</span>
<span class="sd">        fitting but not needed for predicting, for example metrics like the</span>
<span class="sd">        explained variance of predictors. In this case the regressor also needs</span>
<span class="sd">        the method ``average_additional_results(self, list_of_dicts)`` and</span>
<span class="sd">        ``set_additional_results(self, mean_additional_results)``.</span>
<span class="sd">    cv : integer or cross-validation generator (optional, default: None)</span>
<span class="sd">        This determines how the data are split:</span>

<span class="sd">        * If ``cv=None``, 3-fold cross-validation will be used.</span>
<span class="sd">        * If ``cv=n`` where ``n`` is an integer, n-fold cross-validation will be used.</span>
<span class="sd">        * If ``cv=some_object``, where ``some_object`` implements a</span>
<span class="sd">          ``some_object.split(X, y)`` method that returns indices for training</span>
<span class="sd">          and test set, this will be used. It is recommended to use</span>
<span class="sd">          ``YearlyBootstrapper()`` from ``stat_downscaling_tools.bootstrap``.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    mean_coefs : type and shape depends on regressor, (only after fitting)</span>
<span class="sd">        Fitted coefficients (mean of all models where the coefficients</span>
<span class="sd">        were nonzero).</span>
<span class="sd">    cv_error : float (only after fitting)</span>
<span class="sd">        Mean of errors on test sets during bootstrapping loop.</span>

<span class="sd">    If the regressor object has the attributes ``intercept_`` and ``coef_``,</span>
<span class="sd">    these will also be set here.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">regressor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_additional_params</span> <span class="o">=</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;additional_params&#39;</span><span class="p">)</span>

<div class="viewcode-block" id="BootstrappedRegression.fit"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.BootstrappedRegression.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits a model in a bootstrapping loop.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : pd.DataFrame</span>
<span class="sd">            DataFrame of predictors</span>
<span class="sd">        y : pd.Series</span>
<span class="sd">            Series of predictand</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="c1">#assign cross validation scheme</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv</span><span class="p">,</span> <span class="n">classifier</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1"># number of splits in cross-validation:</span>
        <span class="c1"># when using cross-validaton procedures from sklearn, there is sometimes</span>
        <span class="c1"># no attribute cv.n_splits, therefore n_splits has to be get with the </span>
        <span class="c1"># built-in method cv.get_n_splits()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">cv</span><span class="p">,</span> <span class="s1">&#39;n_splits&#39;</span><span class="p">):</span>
            <span class="n">n_splits</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="c1"># otherwise n_splits is just taken directly:</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_splits</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">n_splits</span>

        <span class="n">cv_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_splits</span><span class="p">)</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_additional_results</span><span class="p">:</span>
            <span class="n">additional_results</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
            <span class="c1"># standardize</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">train</span><span class="p">]</span>
            <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
            <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">train</span><span class="p">]</span>
            <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
            <span class="c1"># Regression</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
            <span class="c1"># get coefficients and error</span>
            <span class="n">coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_coefs</span><span class="p">())</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_additional_results</span><span class="p">:</span>
                <span class="n">additional_results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">additional_results</span><span class="p">))</span>
            <span class="n">cv_error</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>


        <span class="c1"># average the coefficients and the additional parameters</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mean_coefs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">average_coefs</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_coefs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mean_coefs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_error</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">has_additional_results</span><span class="p">:</span>
            <span class="n">mean_add_results</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">average_additional_results</span><span class="p">(</span><span class="n">additional_results</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_additional_results</span><span class="p">(</span><span class="n">mean_add_results</span><span class="p">)</span>
        <span class="c1"># set coef_ and intercept_ for ease of use</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">coef_</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="s1">&#39;intercept_&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">intercept_</span></div>



<div class="viewcode-block" id="BootstrappedRegression.predict"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.BootstrappedRegression.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predicts values from previously fitted coefficients.</span>

<span class="sd">        If the input X is a pandas DataFrame or Series, a Series is returned,</span>
<span class="sd">        otherwise only a numpy array.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : pd.DataFrame</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        y : pd.Series</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">y</span></div>

<div class="viewcode-block" id="BootstrappedRegression.fit_predict"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.BootstrappedRegression.fit_predict">[docs]</a>    <span class="k">def</span> <span class="nf">fit_predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div></div>


<div class="viewcode-block" id="ForwardSelection"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection">[docs]</a><span class="k">class</span> <span class="nc">ForwardSelection</span><span class="p">(</span><span class="n">MetaEstimator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs a forward selection regression.</span>

<span class="sd">    This stepwise selects the next most promising candidate predictor and adds</span>
<span class="sd">    it to the model if it is good enough. The method is outlined in</span>
<span class="sd">    &quot;Statistical Analysis in Climate Research&quot; (von Storch, 1999).</span>

<span class="sd">    Since this object is intended to be used in the BootstrappedRegression</span>
<span class="sd">    class, it implements all necessary methods.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    regressor : regression object</span>
<span class="sd">        This should be an object similar to sklearn-like regressors that</span>
<span class="sd">        provides the methods fit and predict. Furthermore, it must also provide</span>
<span class="sd">        the methods ``get_coefs``, ``set_coefs``, ``average_coefs``, and ``fit_active``.</span>
<span class="sd">        An example of this is ``MultipleLSRegression`` below.</span>
<span class="sd">    min_explained_variance : float, optional (default: 0.02)</span>
<span class="sd">        If inclusion of the staged predictor doesn&#39;t improve the explained</span>
<span class="sd">        variance on the test set by at least this amount, stop the selection</span>
<span class="sd">        process.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    explaned_variances : numpy array</span>



<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">min_explained_variance</span><span class="o">=</span><span class="mf">0.02</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">regressor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_explained_variance</span> <span class="o">=</span> <span class="n">min_explained_variance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">additional_results</span> <span class="o">=</span> <span class="p">{}</span>


<div class="viewcode-block" id="ForwardSelection.fit"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Cross-validated forward selection. This fits a regression model</span>
<span class="sd">        according to the following algorithm:</span>

<span class="sd">        1) Start with yhat = mean(y), res = y - yhat, active = []</span>
<span class="sd">        2) for each predictor in inactive set:</span>
<span class="sd">               - add to active set</span>
<span class="sd">               - perform regression</span>
<span class="sd">               - get error and uncertainty of error (standard deviation)</span>
<span class="sd">               - remove from active set</span>
<span class="sd">        3) add predictor with lowest error on test set to active set</span>
<span class="sd">        4) if improvement was not good enough, abort and use previous model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : numpy array of shape #samples x #predictors</span>
<span class="sd">            Array that holds the values of the predictors (columns) at</span>
<span class="sd">            different times (rows) for the training dataset.</span>
<span class="sd">        y_train : numpy array of length #samples</span>
<span class="sd">            Training predictand data</span>
<span class="sd">        X_test : numpy array of shape #samples x #predictors</span>
<span class="sd">            Test predictor data</span>
<span class="sd">        y_test : numpy array of length #samples</span>
<span class="sd">            Test predictand data</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        exp_var : numpy array of length #predictors</span>
<span class="sd">            explained variance of each predictor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get some memory</span>
        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_predictors</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span>

        <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="c1"># deep copy</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span> <span class="c1"># deep copy</span>

        <span class="c1"># I store the index time series in a dictionary, so I can easily</span>
        <span class="c1"># remove the ones we already have and at the same time keep the number</span>
        <span class="c1"># of the index so I can set the correct coefficient.</span>
        <span class="n">X_inactive</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">X_train</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)}</span>
        <span class="n">active</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># initial model: no active predictor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_active</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">active</span><span class="p">)</span>
        <span class="c1">#X_test_active = _get_active(X_test, active)</span>
        
        <span class="n">residual_test</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">SST</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">residual_test</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">explained_variance</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">exp_var_predictors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)</span>
        <span class="n">old_coefs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_coefs</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">):</span>
            <span class="c1"># perform regression with all predictors in inactive set</span>
            <span class="n">inactive_mse_test</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">inactive_mse_train</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">inactive_coefs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">inactive</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">X_inactive</span><span class="p">:</span>
                <span class="n">inactive</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                <span class="n">active</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idx</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fit_active</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">active</span><span class="p">)</span>
                <span class="n">inactive_coefs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_coefs</span><span class="p">())</span>
                <span class="n">residual_test</span> <span class="o">=</span> <span class="n">y_test</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>  <span class="c1"># turn the reset in  _validate_data to False in sklean base</span>
                <span class="n">residual_train</span> <span class="o">=</span> <span class="n">y_train</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
                <span class="n">inactive_mse_test</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">residual_train</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
                <span class="n">inactive_mse_train</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">residual_train</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
                <span class="n">active</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>
            <span class="c1"># find best predictor and add to active set/remove from inactive set</span>
            <span class="n">imax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">inactive_mse_train</span><span class="p">)</span>
            <span class="n">idxmax</span> <span class="o">=</span> <span class="n">inactive</span><span class="p">[</span><span class="n">imax</span><span class="p">]</span>
            <span class="n">SSE</span> <span class="o">=</span> <span class="n">inactive_mse_test</span><span class="p">[</span><span class="n">imax</span><span class="p">]</span>
            <span class="n">new_explained_variance</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">SSE</span><span class="o">/</span><span class="n">SST</span>
            <span class="n">delta_exp_var</span> <span class="o">=</span> <span class="n">new_explained_variance</span> <span class="o">-</span> <span class="n">explained_variance</span>
            <span class="k">if</span> <span class="n">delta_exp_var</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_explained_variance</span><span class="p">:</span>
                <span class="c1"># abort</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_coefs</span><span class="p">(</span><span class="n">old_coefs</span><span class="p">)</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># set the current best parameters as old parameters and start again</span>
                <span class="n">old_coefs</span> <span class="o">=</span> <span class="n">inactive_coefs</span><span class="p">[</span><span class="n">imax</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_coefs</span><span class="p">(</span><span class="n">old_coefs</span><span class="p">)</span>
                <span class="n">active</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">idxmax</span><span class="p">)</span>
                <span class="k">del</span> <span class="n">X_inactive</span><span class="p">[</span><span class="n">idxmax</span><span class="p">]</span>
                <span class="n">exp_var_predictors</span><span class="p">[</span><span class="n">idxmax</span><span class="p">]</span> <span class="o">=</span> <span class="n">delta_exp_var</span>
                <span class="n">explained_variance</span> <span class="o">=</span> <span class="n">new_explained_variance</span>

        <span class="c1"># done we only need to set the explained variance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">additional_results</span><span class="p">[</span><span class="s1">&#39;explained variances&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">exp_var_predictors</span></div>


<div class="viewcode-block" id="ForwardSelection.fit_active"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.fit_active">[docs]</a>    <span class="k">def</span> <span class="nf">fit_active</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">active</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits using only the columns of X whose index is in ``active``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_active</span> <span class="o">=</span> <span class="n">_get_active</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_active</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_expand_coefs</span><span class="p">(</span><span class="n">active</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span></div>

<div class="viewcode-block" id="ForwardSelection.predict"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="ForwardSelection.predict_active"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.predict_active">[docs]</a>    <span class="k">def</span> <span class="nf">predict_active</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">):</span>
        <span class="n">X_active</span> <span class="o">=</span> <span class="n">_get_active</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_active</span><span class="p">)</span></div>

<div class="viewcode-block" id="ForwardSelection.set_additional_results"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.set_additional_results">[docs]</a>    <span class="k">def</span> <span class="nf">set_additional_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">add_results</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">additional_results</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="n">add_results</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">explained_variances</span> <span class="o">=</span> <span class="n">add_results</span><span class="p">[</span><span class="s1">&#39;explained variances&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="ForwardSelection.average_additional_results"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.average_additional_results">[docs]</a>    <span class="k">def</span> <span class="nf">average_additional_results</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">list_of_params</span><span class="p">):</span>
        <span class="n">n_params</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_params</span><span class="p">)</span>
        <span class="n">n_predictors</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">list_of_params</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;explained variances&#39;</span><span class="p">])</span>
        <span class="n">exp_var</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_params</span><span class="p">,</span> <span class="n">n_predictors</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">list_of_params</span><span class="p">):</span>
            <span class="n">exp_var</span><span class="p">[</span><span class="n">i</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="s1">&#39;explained variances&#39;</span><span class="p">]</span>
        <span class="n">add_results</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;explained variances&#39;</span><span class="p">:</span><span class="n">robust_average</span><span class="p">(</span><span class="n">exp_var</span><span class="p">)}</span>
        <span class="k">return</span> <span class="n">add_results</span></div>

<div class="viewcode-block" id="ForwardSelection.average_coefs"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.ForwardSelection.average_coefs">[docs]</a>    <span class="k">def</span> <span class="nf">average_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">list_of_coefs</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">average_coefs</span><span class="p">(</span><span class="n">list_of_coefs</span><span class="p">)</span></div></div>

<span class="c1">###############################################################################################</span>
<span class="c1"># Regressors for Forward Selection</span>
<span class="c1">###############################################################################################</span>


<span class="k">class</span> <span class="nc">LinearCoefsHandlerMixin</span><span class="p">:</span>

    <span class="k">def</span> <span class="nf">get_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns all fitted coefficients in the same order as ``set_coefs`` needs them.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">coefs</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span>
        <span class="n">coefs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">return</span> <span class="n">coefs</span>

    <span class="k">def</span> <span class="nf">set_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coefs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">average_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">list_of_coefs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the average of robust predictors, i.e. of those that are</span>
<span class="sd">        nonzero in at least 50% of the cases.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">list_of_coefs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">robust_average</span><span class="p">(</span><span class="n">coefs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">{}</span>

    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">fit_active</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">active</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fits using only the columns of X whose index is in ``active``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_active</span> <span class="o">=</span> <span class="n">_get_active</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_active</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_expand_coefs</span><span class="p">(</span><span class="n">active</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        
    <span class="k">def</span> <span class="nf">predict_active</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict using only the columns of X whose index is in ``active``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X_active</span> <span class="o">=</span> <span class="n">_get_active</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_active</span><span class="p">)</span>


<div class="viewcode-block" id="MultipleLSRegression"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.MultipleLSRegression">[docs]</a><span class="k">class</span> <span class="nc">MultipleLSRegression</span><span class="p">(</span><span class="n">LinearCoefsHandlerMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of multiple linear OLS regression to be used with</span>
<span class="sd">    ForwardSelection and BootstrappedRegression.</span>
<span class="sd">    The following methods are implemented:</span>

<span class="sd">    - ``fit``</span>
<span class="sd">    - ``predict``</span>
<span class="sd">    - ``get_coefs``</span>
<span class="sd">    - ``set_coefs``</span>
<span class="sd">    - ``average_coefs``</span>
<span class="sd">    - ``fit_active``</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>

<div class="viewcode-block" id="MultipleLSRegression.fit"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.MultipleLSRegression.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># only intercept model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultipleLSRegression.predict"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.MultipleLSRegression.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span></div>

<div class="viewcode-block" id="MultipleLSRegression.set_expand_coefs"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.MultipleLSRegression.set_expand_coefs">[docs]</a>    <span class="k">def</span> <span class="nf">set_expand_coefs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">active</span><span class="p">,</span> <span class="n">n_predictors</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This will be called after ``fit``, since fit will often be called with only some of the</span>
<span class="sd">        predictors. This expands the current coefficients and expands them in a way such that</span>
<span class="sd">        ``predict`` can be called with all predictors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># get a full coefficient vector back</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">active</span><span class="p">):</span>
            <span class="n">coefs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">coefs</span>

        <span class="c1"># get intercept_: if len(active) == 0, the intercept was already set</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">active</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lm</span><span class="o">.</span><span class="n">intercept_</span></div></div>


<span class="c1"># class GammaRegression(LinearCoefsHandlerMixin):</span>
<span class="c1">#     &quot;&quot;&quot;</span>
<span class="c1">#     Implementation of generalized linear gamma regression.</span>
<span class="c1">#     &quot;&quot;&quot;</span>

<span class="c1">#     def __init__(self, family=sm.families.Gamma()):</span>
<span class="c1">#         self.family = family</span>

<span class="c1">#     def fit(self, X, y):</span>
<span class="c1">#         n, m = X.shape</span>
<span class="c1">#         G = np.zeros((n, m+1))</span>
<span class="c1">#         G[:,0:-1] = X</span>
<span class="c1">#         G[:,-1] = np.ones(n)</span>
<span class="c1">#         self.glm = sm.GLM(y, G, family=self.family)</span>
<span class="c1">#         gamma_results = self.glm.fit()</span>
<span class="c1">#         self.coef_ = gamma_results.params[0:-1]</span>
<span class="c1">#         self.intercept_ = gamma_results.params[-1]</span>

<span class="c1">#     def predict(self, X):</span>
<span class="c1">#         n, m = X.shape</span>
<span class="c1">#         G = np.zeros((n, m+1))</span>
<span class="c1">#         G[:,0:-1] = X</span>
<span class="c1">#         G[:,-1] = np.ones(n)</span>
<span class="c1">#         params = np.zeros(len(self.coef_) + 1)</span>
<span class="c1">#         params[0:-1] = self.coef_</span>
<span class="c1">#         params[-1] = self.intercept_</span>
<span class="c1">#         return self.glm.predict(params, exog=G)</span>


<span class="c1">#     def set_expand_coefs(self, active, n_predictors):</span>
<span class="c1">#         # get a full coefficient vector back</span>
<span class="c1">#         coefs = np.zeros(n_predictors)</span>
<span class="c1">#         for i, idx in enumerate(active):</span>
<span class="c1">#             coefs[idx] = self.coef_[i]</span>
<span class="c1">#         self.coef_ = coefs</span>



<span class="c1">###############################################################################################</span>
<span class="c1"># Some functions</span>
<span class="c1">###############################################################################################</span>

<div class="viewcode-block" id="_get_active"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model._get_active">[docs]</a><span class="k">def</span> <span class="nf">_get_active</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">active</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns a new matrix X_active with only the columns of X whose index is in ``active``.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Xnew</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">active</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">active</span><span class="p">):</span>
        <span class="n">Xnew</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="n">idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">Xnew</span></div>

<span class="k">def</span> <span class="nf">robust_average</span><span class="p">(</span><span class="n">coefs</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Takes the robust average of a coefficient matrix.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    coefs : numpy 2d-array, n_coefs x n_predictors</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    mean_coefs : numpy array, length n_predictors</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_coefs</span><span class="p">,</span> <span class="n">n_predictors</span> <span class="o">=</span> <span class="n">coefs</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">mean_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_predictors</span><span class="p">):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">coefs</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="c1"># one column</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">c</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">c</span><span class="p">):</span>
            <span class="n">mean_coefs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mean_coefs</span>



<span class="c1">###############################################################################################</span>
<span class="c1"># Easy to use classes</span>
<span class="c1">###############################################################################################</span>

<div class="viewcode-block" id="BootstrappedForwardSelection"><a class="viewcode-back" href="../../pyESD.html#pyESD.MLR_model.BootstrappedForwardSelection">[docs]</a><span class="k">class</span> <span class="nc">BootstrappedForwardSelection</span><span class="p">(</span><span class="n">BootstrappedRegression</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This is an easy to use interface for BootstrappedRegression with ForwardSelection.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    regressor : regression object</span>
<span class="sd">        This should be an object similar to sklearn-like regressors that</span>
<span class="sd">        provides the methods fit and predict. Furthermore, it must also provide</span>
<span class="sd">        the methods ``get_coefs``, ``set_coefs``, ``average_coefs``, and ``fit_active``.</span>
<span class="sd">        An example of this is ``MultipleLSRegression`` below.</span>
<span class="sd">    min_explained_variance : float, optional (default: 0.02)</span>
<span class="sd">        If inclusion of the staged predictor doesn&#39;t improve the explained</span>
<span class="sd">        variance on the test set by at least this amount, stop the selection</span>
<span class="sd">        process.</span>
<span class="sd">    cv : integer or cross-validation generator (optional, default: None)</span>
<span class="sd">        This determines how the data are split:</span>

<span class="sd">        * If ``cv=None``, 3-fold cross-validation will be used.</span>
<span class="sd">        * If ``cv=n`` where ``n`` is an integer, n-fold cross-validation will be used.</span>
<span class="sd">        * If ``cv=some_object``, where ``some_object`` implements a</span>
<span class="sd">          ``some_object.split(X, y)`` method that returns indices for training</span>
<span class="sd">          and test set, this will be used. It is recommended to use</span>
<span class="sd">          ``YearlyBootstrapper()`` from ``stat_downscaling_tools.bootstrap``.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">min_explained_variance</span><span class="o">=</span><span class="mf">0.02</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">ForwardSelection</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">min_explained_variance</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">has_additional_results</span> <span class="o">=</span> <span class="kc">True</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Daniel Boateng.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>