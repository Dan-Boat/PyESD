{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69ebdfe0",
   "metadata": {},
   "source": [
    "## Model selection \n",
    "\n",
    "Here, we demonstrate the modeling framework of experimenting the performance of many ML models to decide the best for the weather stations considered here. We follow the previous exercise on predictor selection method and the other related steps. The only thing we are adding here is to define many learning models, trained them individually to evaluate their performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67384caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the models required\n",
    "import os \n",
    "import sys \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from collections import OrderedDict\n",
    "import socket\n",
    "\n",
    "# modules related to pyESD\n",
    "\n",
    "from pyESD.Weatherstation import read_station_csv\n",
    "from pyESD.standardizer import MonthlyStandardizer\n",
    "from pyESD.ESD_utils import store_pickle, store_csv\n",
    "from pyESD.splitter import KFold\n",
    "from pyESD.ESD_utils import Dataset\n",
    "from pyESD.Weatherstation import read_weatherstationnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34889b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the predictors without teleconnection indices\n",
    "predictors = [\"t2m\", \"tp\",\"msl\", \"v10\", \"u10\", \"NAO\", \"EA\", \"SCAN\", \"EAWR\",\n",
    "              \"u250\", \"u850\", \"u500\",\"u700\", \"u1000\",\"v250\", \"v850\", \"v500\",\"v700\", \"v1000\",\n",
    "              \"r250\", \"r850\", \"r500\",\"r700\", \"r1000\", \"z250\", \"z500\", \"z700\", \"z850\", \"z1000\", \n",
    "              \"t250\", \"t850\", \"t500\",\"t700\", \"t1000\",\"dtd250\", \"dtd850\", \"dtd500\",\"dtd700\", \"dtd1000\"\n",
    "              ]\n",
    "\n",
    "# date-range for model training and validation\n",
    "from1958to2010 = pd.date_range(start=\"1958-01-01\", end=\"2010-12-31\", freq=\"MS\")\n",
    "\n",
    "# date-range for testing model\n",
    "from2011to2020 = pd.date_range(start=\"2011-01-01\", end=\"2020-12-31\", freq=\"MS\")\n",
    "\n",
    "#full-time range\n",
    "from1958to2020 = pd.date_range(start=\"1958-01-01\", end=\"2020-12-31\", freq=\"MS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2c9b53",
   "metadata": {},
   "source": [
    "### control function\n",
    "\n",
    "Define the control function that performs the predictor selection and model training.\n",
    "1. read the station data as object that would apply all the ESD routines\n",
    "2. set predictors with the list of predictors defined and the radius to construct the regional means\n",
    "3. standardize the data with any of the standardizers. Here we use the MonthlyStandardizer method\n",
    "4. defined the scoring metrics to be used for the validation\n",
    "5. set the model to be used for the ESD training (here we will use the LassoLarsCV model)\n",
    "6. fit the model, here we have to define the predictor selector method (here: Recursive ) to be used for selecting the predictors\n",
    "7. get the selected predictors \n",
    "8. use the cross_validate_predict to get the cross-validation metrics of the model training \n",
    "9. store the selected predictors \n",
    "10. stored the validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "771ca845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_selection(variable, estimator, cachedir, stationnames,\n",
    "                    station_datadir, radius, base_estimators=None,\n",
    "                       final_estimator=None):\n",
    "    \"\"\"\n",
    "    Run an experiment using pyESD to perform predictor selection for a given variable.\n",
    "\n",
    "    Args:\n",
    "        variable (str): The target variable to predict, here Precipitation.\n",
    "        regressor (str): The regression method to use, here we use the RidgeCV regression to test all the predictor selection\n",
    "        methods.\n",
    "        selector_method (str): The method for selecting predictors (\"Recursive\", \"TreeBased\", \"Sequential\").\n",
    "        cachedir (str): Directory to store cached results, here all the files would be stored in the .\n",
    "        stationnames (list): List of station names. it would be loaded from the read_data file\n",
    "        station_datadir (str): Directory containing station data files: this is also set in the read the data file\n",
    "        predictors (list): List of predictor variables.\n",
    "        predictordir (str): Directory containing predictor data files.\n",
    "        radius (float): Radius for selecting predictors: also defined in the read_data file\n",
    "        base_estimators (list): for stacking regressor base models \n",
    "        final_estimator (str): for stacking regressor meta-learner\n",
    "    \"\"\"\n",
    "    num_of_stations = len(stationnames)\n",
    "\n",
    "    # Loop through all stations\n",
    "    for i in range(num_of_stations):\n",
    "        stationname = stationnames[i]\n",
    "        \n",
    "        # set the exact path for the station  data\n",
    "        station_dir = os.path.join(station_datadir, stationname + \".csv\")\n",
    "        \n",
    "        # 1. create the station object using the read_station_csv and apply all the methods on the station object\n",
    "        \n",
    "        SO_instance = read_station_csv(filename=station_dir, varname=variable)\n",
    "\n",
    "        # 2. Setting predictors (generate the predictors using the defined predictor names)\n",
    "        SO_instance.set_predictors(variable, predictors, predictordir, radius)\n",
    "\n",
    "        # 3. Setting standardizer\n",
    "        SO_instance.set_standardizer(variable, standardizer=MonthlyStandardizer(detrending=False, scaling=False))\n",
    "        \n",
    "        \n",
    "        # 4. define the scoring metrics\n",
    "        scoring = [\"neg_root_mean_squared_error\", \"r2\", \"neg_mean_absolute_error\"]\n",
    "        \n",
    "        # 5. Setting model with cross-validation\n",
    "        if estimator == \"Stacking\":\n",
    "            \n",
    "            SO_instance.set_model(variable, method=estimator, ensemble_learning=True, \n",
    "                     estimators=base_estimators, final_estimator_name=final_estimator, daterange=from1958to2010,\n",
    "                     predictor_dataset=ERA5Data, cv=KFold(n_splits=10),\n",
    "                     scoring = scoring)\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            SO_instance.set_model(variable, method=estimator, cv=KFold(n_splits=10),\n",
    "                         scoring = scoring)\n",
    "\n",
    "        # 6. Fitting model with predictor selector option\n",
    "        SO_instance.fit(variable, from1958to2010, ERA5Data, fit_predictors=True, predictor_selector=True,\n",
    "                            selector_method=\"Recursive\", selector_regressor=\"ARD\",\n",
    "                            cal_relative_importance=False)\n",
    "        \n",
    "        # 7. cross-validate and predict\n",
    "        score_fit, ypred_fit = SO_instance.cross_validate_and_predict(variable,  from1958to2010, ERA5Data,)\n",
    "\n",
    "        # 8. evaluate model on the test set\n",
    "        score_test = SO_instance.evaluate(variable,  from2011to2020, ERA5Data,)\n",
    "        \n",
    "        # 9. make predictions for the test and train period\n",
    "        ypred_train = SO_instance.predict(variable, from1958to2010, ERA5Data)\n",
    "        \n",
    "        ypred_test = SO_instance.predict(variable, from2011to2020, ERA5Data)\n",
    "        \n",
    "        # get the observed datasets for comparisons \n",
    "        y_obs_train = SO_instance.get_var(variable, from1958to2010, anomalies=True)\n",
    "        \n",
    "        y_obs_test = SO_instance.get_var(variable, from2011to2020, anomalies=True)\n",
    "        \n",
    "        y_obs_full = SO_instance.get_var(variable, from1958to2020, anomalies=True)\n",
    "\n",
    "        # 9-10. Storing results using pickle\n",
    "        predictions = pd.DataFrame({\n",
    "            \"obs_full\": y_obs_full,\n",
    "            \"obs_train\" : y_obs_train,\n",
    "            \"obs_test\": y_obs_test,\n",
    "            \"ERA5 1958-2010\" : ypred_train,\n",
    "            \"ERA5 2011-2020\" : ypred_test})\n",
    "        \n",
    "        \n",
    "        store_pickle(stationname, \"validation_score_\" + estimator, score_fit, cachedir)\n",
    "        store_pickle(stationname, \"test_score_\" + estimator, score_test, cachedir)\n",
    "        store_csv(stationname, \"predictions_\" + estimator, predictions, cachedir)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ede7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_data import radius, station_prec_datadir, stationnames_prec, ERA5Data, predictordir, cachedir_prec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f15f764",
   "metadata": {},
   "source": [
    "## Perfom the experiment for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea05988",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator = \"LassoLarsCV\"\n",
    "\n",
    "base_estimators = [\"LassoLarsCV\", \"ARD\", \"MLP\", \"RandomForest\", \"XGBoost\", \"Bagging\"]\n",
    "\n",
    "\n",
    "estimators = [\"LassoLarsCV\", \"ARD\", \"MLP\", \"RandomForest\", \"XGBoost\", \"Bagging\", \"Stacking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bae8e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freiburg 48.0232 7.8343 236.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not Dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34768/2829320175.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimators\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     run_model_selection(variable=\"Precipitation\", estimator=estimator, cachedir=cachedir_prec, stationnames=stationnames_prec,\n\u001b[0m\u001b[0;32m      3\u001b[0m                         \u001b[0mstation_datadir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstation_prec_datadir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictordir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mERA5Data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                         \u001b[0mradius\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mradius\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                            final_estimator=final_estimator)\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34768/577638659.py\u001b[0m in \u001b[0;36mrun_model_selection\u001b[1;34m(variable, estimator, cachedir, stationnames, station_datadir, predictors, predictordir, radius, base_estimators, final_estimator)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# 6. Fitting model with predictor selector option\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         SO_instance.fit(variable, from1958to2010, ERA5Data, fit_predictors=True, predictor_selector=True,\n\u001b[0m\u001b[0;32m     59\u001b[0m                             \u001b[0mselector_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Recursive\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselector_regressor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ARD\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m                             cal_relative_importance=False)\n",
      "\u001b[1;32mc:\\users\\dboateng\\desktop\\python_scripts\\esd_package\\pyESD\\StationOperator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, variable, daterange, predictor_dataset, fit_predictors, predictor_selector, selector_method, selector_regressor, num_predictors, selector_direction, cal_relative_importance, fit_predictand, impute, impute_method, impute_order, **predictor_kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         return self.variables[variable].fit(daterange , predictor_dataset, fit_predictors=fit_predictors , predictor_selector=predictor_selector, \n\u001b[0m\u001b[0;32m    129\u001b[0m                                             \u001b[0mselector_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mselector_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[0mselector_regressor\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mselector_regressor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dboateng\\desktop\\python_scripts\\esd_package\\pyESD\\predictand.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, daterange, predictor_dataset, fit_predictors, predictor_selector, selector_method, selector_regressor, num_predictors, selector_direction, cal_relative_importance, fit_predictand, impute, impute_method, impute_order, **predictor_kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_predictor_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_predictors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_predictors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredictor_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manomalies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_predictand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dboateng\\desktop\\python_scripts\\esd_package\\pyESD\\predictand.py\u001b[0m in \u001b[0;36m_get_predictor_data\u001b[1;34m(self, daterange, dataset, fit_predictors, **predictor_kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 148\u001b[1;33m             \u001b[0mXs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdaterange\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_predictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dboateng\\desktop\\python_scripts\\esd_package\\pyESD\\Predictor_Base.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, daterange, dataset, fit, regenerate, patterns_from, params_from)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mregenerate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dboateng\\desktop\\python_scripts\\esd_package\\pyESD\\Predictor_Base.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mfilename_to_store\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcachedir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlongname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_to_store\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\ESD\\lib\\ntpath.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;31m# Join two (or more) paths.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mb'\\\\'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Dataset"
     ]
    }
   ],
   "source": [
    "for estimator in estimators:\n",
    "    run_model_selection(variable=\"Precipitation\", estimator=estimator, cachedir=cachedir_prec, stationnames=stationnames_prec,\n",
    "                        station_datadir=station_prec_datadir,\n",
    "                        radius=radius, base_estimators=base_estimators,\n",
    "                           final_estimator=final_estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a474356f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedffba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7dcfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad693da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5143579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10558ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d340fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc293bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d51e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d670a444",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
